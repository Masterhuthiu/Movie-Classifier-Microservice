import os
import socket
import certifi
import consul
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel
from pymongo import MongoClient
from google import genai  # üî• D√πng cho google-genai==0.3.0
from google.genai import types
from typing import List

# ===============================
# 1. C·∫§U H√åNH (CONFIG)
# ===============================
MONGO_URI = os.getenv(
    "MONGO_URI",
    "mongodb+srv://masterhuthiu:123456a%40A@cluster0.3jl7a.mongodb.net/?retryWrites=true&w=majority",
)
GEMINI_API_KEY ="AIzaSyDDlIjhAUI2H1tIxzzWguWKZ3IeEysAsME" #os.getenv("GEMINI_API_KEY")
PORT = int(os.getenv("PORT", 8083))

DB_NAME = "sample_mflix"
COLLECTION_NAME = "movies"
VECTOR_INDEX_NAME = "movies_vector_index"
VECTOR_FIELD_PATH = "fullplot_gemini_embedding"

# T√™n model ƒë·∫ßy ƒë·ªß theo chu·∫©n SDK m·ªõi
EMBEDDING_MODEL = "models/gemini-embedding-001" 

# ===============================
# 2. KH·ªûI T·∫†O SERVICES
# ===============================
client = MongoClient(MONGO_URI, tlsCAFile=certifi.where())
db = client[DB_NAME]
movies_col = db[COLLECTION_NAME]

# Kh·ªüi t·∫°o Client
try:
    if GEMINI_API_KEY:
        ai_client = genai.Client(api_key=GEMINI_API_KEY)
        print(f"‚úÖ Gemini Client initialized. Model: {EMBEDDING_MODEL}")
    else:
        ai_client = None
        print("‚ùå CRITICAL: GEMINI_API_KEY is missing from Env!")
except Exception as e:
    ai_client = None
    print(f"‚ùå Failed to init Gemini Client: {e}")

class MovieQuery(BaseModel):
    description: str

# ===============================
# 3. CONSUL & LIFESPAN
# ===============================
def register_to_consul():
    try:
        consul_host = os.getenv("CONSUL_HOST", "consul-server")
        c = consul.Consul(host=consul_host, port=8500)
        hostname = socket.gethostname()
        ip_addr = socket.gethostbyname(hostname)

        c.agent.service.register(
            name="movie-classifier-service",
            service_id=f"classifier-{PORT}",
            address=ip_addr,
            port=PORT,
            check=consul.Check.http(f"http://{ip_addr}:{PORT}/health", interval="10s"),
        )
        print(f"‚úÖ Registered to Consul: {ip_addr}:{PORT}")
    except Exception as e:
        print(f"‚ùå Consul Error: {e}")

@asynccontextmanager
async def lifespan(app: FastAPI):
    register_to_consul()
    yield
    print("üîª Shutting down...")

app = FastAPI(title="Movie AI Classifier", lifespan=lifespan)

# ===============================
# 4. AI LOGIC (Embedding)
# ===============================
def get_single_embedding(text: str):
    """T·∫°o vector 768-dims v√† in l·ªói chi ti·∫øt n·∫øu th·∫•t b·∫°i"""
    try:
        if not text or ai_client is None:
            print("‚ö†Ô∏è Embedding skip: Text empty or Client not ready")
            return None

        # G·ªçi API t·∫°o vector
        result = ai_client.models.embed_content(
            model=EMBEDDING_MODEL,
            contents=text,
            config=types.EmbedContentConfig(task_type="RETRIEVAL_QUERY")
        )

        if result and result.embeddings:
            return result.embeddings[0].values
        
        print("‚ö†Ô∏è Gemini returned empty embeddings list")
        return None

    except Exception as e:
        # ‚ö° ƒê√ÇY L√Ä D√íNG QUAN TR·ªåNG ƒê·ªÇ DEBUG TR√äN K8S
        print(f"üî• Gemini Error Detail: {str(e)}")
        return None

def background_sync_embeddings():
    print("üîÑ Background sync started...")
    query = {"fullplot": {"$exists": True}, VECTOR_FIELD_PATH: {"$exists": False}}
    cursor = movies_col.find(query).limit(50)
    updated = 0
    for doc in cursor:
        vector = get_single_embedding(doc["fullplot"])
        if vector:
            movies_col.update_one({"_id": doc["_id"]}, {"$set": {VECTOR_FIELD_PATH: vector}})
            updated += 1
    print(f"‚úÖ Sync done. Updated {updated} docs.")

# ===============================
# 5. API ENDPOINTS
# ===============================
@app.post("/classify")
async def classify_movie(query: MovieQuery):
    try:
        # 1. T·∫°o embedding
        user_vector = get_single_embedding(query.description)
        if not user_vector:
            # Tr·∫£ v·ªÅ l·ªói chi ti·∫øt h∆°n thay v√¨ 500 chung chung
            raise HTTPException(status_code=500, detail="Gemini failed. Check Pod logs for üî• error.")

        # 2. Vector Search
        pipeline = [
            {
                "$vectorSearch": {
                    "index": VECTOR_INDEX_NAME,
                    "path": VECTOR_FIELD_PATH,
                    "queryVector": user_vector,
                    "numCandidates": 100,
                    "limit": 5,
                }
            },
            {
                "$project": {
                    "title": 1, "genres": 1, "score": {"$meta": "vectorSearchScore"}
                }
            },
        ]

        neighbors = list(movies_col.aggregate(pipeline))

        if not neighbors:
            return {"predicted_genre": "Unknown", "message": "No matches in DB"}

        # 3. Predict Genre
        all_genres = []
        for n in neighbors:
            all_genres.extend(n.get("genres", []))
        
        predicted = max(set(all_genres), key=all_genres.count) if all_genres else "Unknown"

        return {
            "predicted_genre": predicted,
            "confidence": neighbors[0].get("score", 0),
            "matches": neighbors
        }

    except Exception as e:
        print(f"‚ùå API Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/admin/sync-embeddings")
async def trigger_sync(background_tasks: BackgroundTasks):
    background_tasks.add_task(background_sync_embeddings)
    return {"message": "Syncing..."}

@app.get("/health")
def health():
    return {"status": "ok", "model": EMBEDDING_MODEL, "api_ready": ai_client is not None}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=PORT)